
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<title>DualLip: A System for Joint Lip Reading and Generation</title>

<!-- Meta tags for search engines to crawl -->
<meta name="robots" content="index,follow">
<meta name="description" content="Lip reading aims to recognize text from talking lip, while lip generation aims to synthesize talking lip according to text, which is a key component in talking face generation and is a dual task of lip reading. In this paper, we develop DualLip, a system that jointly improves lip reading and generation by leveraging the task duality and using unlabeled text and lip video data. The key ideas of the DualLip include: 1) Generate lip video from unlabeled text with a lip generation model, and use the pseudo pairs to improve lip reading; 2) Generate text from unlabeled lip video with a lip reading model, and use the pseudo pairs to improve lip generation. We further extend DualLip to talking face generation with two additionally introduced components: lip to face generation and text to speech generation. Experiments on GRID and TCD-TIMIT demonstrate the effectiveness of DualLip on improving lip reading, lip generation, and talking face generation by utilizing unlabeled data. Specifically, the lip generation model in our DualLip system trained with only 10% paired data surpasses the performance of that trained with the whole paired data. And on the GRID benchmark of lip reading, we achieve 1.16% character error rate and 2.71% word error rate, outperforming the state-of-the-art models using the same amount of paired data.">
<meta name="keywords" content="lip reading;lip generation;task duality;talking face generation;lip to face;text to speech;">
<link rel="author" href="https://dualip.github.io/">

<!-- Fonts and stuff -->
<link href="./DualLip/css" rel="stylesheet" type="text/css">
<link rel="stylesheet" type="text/css" href="./DualLip/project.css" media="screen">
<link rel="stylesheet" type="text/css" media="screen" href="./DualLip/iconize.css">
<script async="" src="./DualLip/prettify.js"></script>

</head>

<body>
  <div id="content">
    <div id="content-inner">
      <div class="section head">

      <h1>DualLip: A System for Joint Lip Reading and Generation</h1>

      <div class="authors">
        <a href="https://nicsefc.ee.tsinghua.edu.cn/people/weicong-chen/">Weicong Chen<sup>1</sup></a>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
	    <a href="https://www.microsoft.com/en-us/research/people/xuta/">Xu Tan<sup>2</sup></a>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
	    <a href="https://www.microsoft.com/en-us/research/people/yinxia/">Yingce Xia<sup>2</sup></a>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
        </br>
	    <a href="https://www.microsoft.com/en-us/research/people/taoqin/">Tao Qin<sup>2</sup></a>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
        <a href="https://nicsefc.ee.tsinghua.edu.cn/people/yu-wang/">Yu Wang<sup>1</sup></a>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
	    <a href="https://www.microsoft.com/en-us/research/people/tyliu/">Tieyan Liu<sup>2</sup></a>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
      </div>

      <div class="affiliations">
          <p> <sup>1</sup>Tsinghua University, <sup>2</sup>Microsoft Research Asia </p>
      </div>


      <div class="venue">ACM Multimedia Conference (<a href="https://2020.acmmm.org/index.html" target="_blank">MM</a>) 2020, <font color="#e86e14">Accepted</font> </div>
    </div>

      <center><img src="./DualLip/intro.png" border="0" width="90%"></center>




<div class="section abstract">
  <h2>Abstract</h2>
  <br>
  <p>
Lip reading aims to recognize text from talking lip, while lip generation aims to synthesize talking lip according to text, which is a key component in talking face generation and is a dual task of lip reading. In this paper, we develop DualLip, a system that jointly improves lip reading and generation by leveraging the task duality and using unlabeled text and lip video data. The key ideas of the DualLip include: 1) Generate lip video from unlabeled text with a lip generation model, and use the pseudo pairs to improve lip reading; 2) Generate text from unlabeled lip video with a lip reading model, and use the pseudo pairs to improve lip generation. We further extend DualLip to talking face generation with two additionally introduced components: lip to face generation and text to speech generation. Experiments on GRID and TCD-TIMIT demonstrate the effectiveness of DualLip on improving lip reading, lip generation, and talking face generation by utilizing unlabeled data. Specifically, the lip generation model in our DualLip system trained with only10% paired data surpasses the performance of that trained with the whole paired data. And on the GRID benchmark of lip reading, we achieve 1.16% character error rate and 2.71% word error rate, outperforming the state-of-the-art models using the same amount of paired data.
  </p>
</div>



<div class="section demo">
  <h2>Demo Video for Talking Face Generation</h2>
  <br>
  <center>
    <!--
    <video width="640" height="400" controls>
      <source src="./DualLip/lip2face_demo_new1.mp4">
    </video>
    -->
    <iframe width="560" height="315" src="https://www.youtube.com/embed/ClZEQBS_ctk" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
  </center>
</div>

<br>
<!--

<div class="section materials">
  <h2>Materials</h2>
  <center>
    <ul>
      <li class="grid">
        <div class="griditem">
          <a href="https://www.google.com" target="_blank" class="imageLink"><img src="./DualLip/paper.jpg"></a><br>
          <a href="https://www.google.com" target="_blank">Paper</a>
        </div>
      </li>

    </ul>
  </center>
</div>

<br>

<div class="section code">
  <h2>Code and Models</h2>
  <center>
    <ul>
      <li class="grid">
        <div class="griditem">
          <a href="https://www.google.com" target="_blank" class="imageLink"><img src="./DualLip/code.png"></a><br>
          <a href="https://www.google.com" target="_blank">Code and Models</a>
        </div>
      </li>

    </ul>
  </center>
</div>

<br>

<div class="section citation">
  <h2>Citation</h2>
  <div class="section bibtex">
    <pre>@inproceedings
    }</pre>
</div>
-->

</div>

</body></html>
